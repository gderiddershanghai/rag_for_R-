{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b81796-804e-4cf5-9e07-962b7b2e2a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b831e97-0bf6-4d4b-953a-64b95e637a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"data/R_for_Data_Science.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05a70d9d-7a47-4887-8ef6-ed38a764b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(fp)\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a49efca5-02b0-4a20-85f4-9099a08e6d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e0e322d-fadb-448c-95d7-8ffc8e95d37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.224\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "print(pkg_resources.get_distribution('langchain').version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5066d8c3-df66-43e3-8b52-655a4db2b4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e64d0d66-346e-4289-a291-8b3ff39b6ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fba78e7-c4cc-48ef-99ea-bd0e5d6fcecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/langchain_core/pydantic_v1/__init__.py\", line 15, in <module>\n",
      "    from pydantic.v1 import *  # noqa: F403 # type: ignore\n",
      "ModuleNotFoundError: No module named 'pydantic.v1'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_27163/3836268852.py\", line 1, in <module>\n",
      "    from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/langchain/text_splitter.py\", line 52, in <module>\n",
      "    from langchain_core.documents import BaseDocumentTransformer, Document\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/langchain_core/documents/__init__.py\", line 1, in <module>\n",
      "    from langchain_core.documents.base import Document\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/langchain_core/documents/base.py\", line 5, in <module>\n",
      "    from langchain_core.load.serializable import Serializable\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/langchain_core/load/__init__.py\", line 2, in <module>\n",
      "    from langchain_core.load.dump import dumpd, dumps\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/langchain_core/load/dump.py\", line 4, in <module>\n",
      "    from langchain_core.load.serializable import Serializable, to_json_not_implemented\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/langchain_core/load/serializable.py\", line 4, in <module>\n",
      "    from langchain_core.pydantic_v1 import BaseModel, PrivateAttr\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/langchain_core/pydantic_v1/__init__.py\", line 17, in <module>\n",
      "    from pydantic import *  # noqa: F403 # type: ignore\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pydantic/__init__.py\", line 370, in __getattr__\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"pydantic/dataclasses.py\", line 43, in init pydantic.dataclasses\n",
      "  File \"pydantic/class_validators.py\", line 8, in init pydantic.class_validators\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pydantic/_migration.py\", line 302, in wrapper\n",
      "pydantic.errors.PydanticImportError: `pydantic.errors:ConfigError` has been removed in V2.\n",
      "\n",
      "For further information visit https://errors.pydantic.dev/2.5/u/import-error\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 812, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 730, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/executing/executing.py\", line 168, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44781b22-f3c0-4a1a-a836-04fe7e131c1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RecursiveCharacterTextSplitter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m character_splitter \u001b[38;5;241m=\u001b[39m \u001b[43mRecursiveCharacterTextSplitter\u001b[49m(\n\u001b[1;32m      2\u001b[0m     separators\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      3\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m      4\u001b[0m     chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m character_split_texts \u001b[38;5;241m=\u001b[39m character_splitter\u001b[38;5;241m.\u001b[39msplit_text(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(pdf_texts))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(word_wrap(character_split_texts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RecursiveCharacterTextSplitter' is not defined"
     ]
    }
   ],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "print(word_wrap(character_split_texts[-1]))\n",
    "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1944f68-2989-496b-b198-1fdbfdc79f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "\n",
    "print(word_wrap(token_split_texts[10]))\n",
    "print(f\"\\nTotal chunks: {len(token_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31239bfb-cc8d-4673-a133-be6d1ba50a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(fp, embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1508e919-7f10-4d09-a504-0ee30184d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who are the biggest competitors of Microsoft?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(word_wrap(document))\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
