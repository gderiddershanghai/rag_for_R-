{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57b81796-804e-4cf5-9e07-962b7b2e2a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pypdf import PdfReader\n",
    "# # from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65776f45-b1cb-409c-a3f8-65ac697341ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = 'data/TheRBook.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18b45ad6-dc5a-4b00-8161-244a0cf47bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbcc17ee-f6b1-44e5-8a9c-e09d73fdf6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = utils.get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfbc8cab-c051-4a09-a18b-cbec14f568e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[fp]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04ba4dfa-0818-418f-ad74-4915117a14a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "1060 \n",
      "\n",
      "<class 'llama_index.schema.Document'>\n",
      "Doc ID: 2ba6c3eb-1702-4eb2-a40b-7768e611d37c\n",
      "Text: The R Book\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e4203f3-baa6-4900-bae5-664e24abaf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e799318a-9eca-4ca8-8401-cb149b736d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, \n",
    ")\n",
    "# embed_model=\"local:BAAI/bge-small-en-v1.5\"\n",
    "index = VectorStoreIndex.from_documents([document],\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db41da7e-8b09-420f-8190-e3aca3b91627",
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d060db3-b031-4399-b1b8-b5213c948c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "how do I convert a dataframe to a table?\n",
    "\"\"\"\n",
    "answer = retriever.retrieve(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b633cc4-4fc4-4318-b93c-d9696b1c27cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='b32c4e05-3d6b-4e7f-8893-a2c34d7e0612', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='fdd2e414-0176-49c2-94d6-48fb44cc515a', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='95b79960d97ad91c780dee264d78cb06a2fd765ad9031743ff6c4a322ae6ffe3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3beb7f30-9c33-4bb5-b9e6-cabf79d51f0c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0aadf2ef20e43893512b505f8e9836519d705ff8ac100d9a053fb2c8bf6efc36'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='93ff048f-829c-4b79-a7ee-3502f107bc22', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dad609f1f2353e6c4da312c0e0562cbec3b9595d9446d7f371f05103f5b31fbd')}, hash='7b5958be8908f11d0724b3c5589c8c891f6fd0462119c49938ae6d8978338b0a', text='the animals’ body weights). The alternative is to produce a long vector of row numbers\\n\\n252 THE R BOOK\\nand use this as a subscript on the rows of the short dataframe to turn it into a long dataframe with the same\\ncolumn structure (this is illustrated on p. 255).\\n6.4 Converting from a dataframe to a table\\nThe reverse procedure of creating a table from a dataframe is much more straightforward, and involves\\nnothing more than the table function:\\ntable(dbtable)\\n, ,condition = healthy\\nAge\\nsex old young\\nfemale 8 9\\nmale 7 12\\n, ,condition = parasitized\\nAge\\nsex old young\\nfemale 5 8\\nmale 7 6\\nY ou might want this tabulated object itself to be another dataframe, in which case use:as.data.frame(table(dbtable))\\nsex age condition Freq\\n1 female old healthy 8\\n2 male old healthy 7\\n3 female young healthy 9\\n4 male young healthy 125 female old parasitized 5\\n6 male old parasitized 7\\n7 female young parasitized 88 male young parasitized 6\\nY ou will see that R has invented the variable name Freq for the counts of the various contingencies. To\\nchange this to ‘count’ use names with the appropriate subscript [4] :\\nframe<-as.data.frame(table(dbtable))\\nnames(frame)[4]<-\"count\"frame\\nsex age condition count\\n1 female old healthy 8\\n2 male old healthy 7\\n3 female young healthy 94 male young healthy 12\\n5 female old parasitized 5\\n6 male old parasitized 77 female young parasitized 8\\n8 male young parasitized 6\\n\\nTABLES 253\\n6.5 Calculating tables of proportions with prop.table\\nThe margins of a table (the row totals or the column totals) are often useful for calculating proportions\\ninstead of counts. Here is a data matrix called counts :\\ncounts<-matrix(c(2,2,4,3,1,4,2,0,1,5,3,3),nrow=4)\\ncounts\\n[,1] [,2] [,3]\\n[1,] 2 1 1\\n[2,] 2 4 5\\n[3,] 4 2 3\\n[4,] 3 0 3\\nThe proportions will be different when they are expressed as a fraction of the row totals or of the column\\ntotals. To ﬁnd the proportions we use prop.table(counts,margin) . Y ou need to remember that the\\nrow subscripts come ﬁrst, which is why margin=1 refers to the row totals:\\nprop.table(counts,1)\\n[,1] [,2] [,3]\\n[1,] 0.5000000 0.2500000 0.2500000[2,] 0.1818182 0.3636364 0.4545455\\n[3,] 0.4444444 0.2222222 0.3333333\\n[4,] 0.5000000 0.0000000 0.5000000\\nUsemargin=2 to express the counts as proportions of the relevant column total:\\nprop.table(counts,2)\\n[,1] [,2] [,3]\\n[1,] 0.1818182 0.1428571 0.08333333\\n[2,] 0.1818182 0.5714286 0.41666667[3,] 0.3636364 0.2857143 0.25000000\\n[4,] 0.2727273 0.0000000 0.25000000\\nTo check that the column proportions sum to 1, use colSums like this:\\ncolSums(prop.table(counts,2))\\n[ 1 ]111\\nIf you want the proportions expressed as a fraction of the grand total sum(counts) , then simply omit the\\nmargin number:\\nprop.table(counts)\\n[,1] [,2] [,3]\\n[1,] 0.06666667 0.03333333 0.03333333\\n[2,] 0.06666667 0.13333333 0.16666667\\n[3,] 0.13333333 0.06666667 0.10000000\\n[4,] 0.10000000 0.00000000 0.10000000\\nsum(prop.table(counts))\\n[1] 1\\n\\n254 THE R BOOK\\nIn any particular case, you need to think carefully whether it makes sense to express your counts as proportions\\nof the row totals, the column totals or the grand total.', start_char_idx=484421, end_char_idx=487501, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[0].node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8ee4627-39ed-453b-821f-2708543d612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31f7ec3a-14aa-48f9-aad6-fac4a49a1adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a simple linear regression model, you will need to use the appropriate statistical package in R. You can start by loading the necessary package at the top of your script. Then, you will need to prepare your data by creating a data frame or matrix with your predictor variable(s) and response variable. Once your data is ready, you can use the lm() function to fit the linear regression model. The lm() function takes the form of \"response ~ predictor\" where you replace \"response\" with the name of your response variable and \"predictor\" with the name of your predictor variable. Finally, you can use summary() to view the results of your linear regression model, including the coefficients and p-values.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"How do I create a simple linear regression model?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b73257f2-1029-402b-9620-777df68465bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='0aa3a0a0-adda-4cf1-95cb-760ffdf97887', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='6a01f67d-814e-4dcb-9267-5939e8474d9f', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='066f44e9c566b4ad5a8851673fe629f8cd260e4f653cd4067a318e8c4adfc5ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3663fe51-16c9-4a47-8615-d46f0d78b3e1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d672dfdb55f975d4242c3c0a119584e83505f7a9cc3dbd8ee3f2a41286239e97'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='071c31dd-a56e-4d5f-8bdc-5fc6adc30b09', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9e1ea05ab01fc0816bfb95237e81ba5ad71b74e7a2ddd004b98a783285efed6a')}, hash='61560c78acbf042a608e975e48f7098b5d336580d21534d28fd558d69e4656c0', text='The\\neasiest way to make sure you’ve done this is using the reprex package.\\n•Second, you need to make it minimal. Strip away everything that is not directly•\\nrelated to your problem. This usually involves creating a much smaller and\\nsimpler R object than the one you’re facing in real life or even using built-in data.\\nThat sounds like a lot of work! And it can be, but it has a great payoff:\\n•80% of the time, creating an excellent reprex reveals the source of your problem.•\\nIt’s amazing how often the process of writing up a self-contained and minimal\\nexample allows you to answer your own question.\\n•The other 20% of the time, you will have captured the essence of your problem•\\nin a way that is easy for others to play with. This substantially improves your\\nchances of getting help!\\nWhen creating a reprex by hand, it’s easy to accidentally miss something, meaning\\nyour code can’t be run on someone else’s computer. Avoid this problem by using the\\nreprex package, which is installed as part of the tidyverse. Let’s say you copy this code\\nonto your clipboard (or, on RStudio Server or Cloud, select it):\\ny <- 1:4\\nmean(y)\\nThen call reprex() , where the default output is formatted for GitHub:\\nreprex::reprex()\\nA nicely rendered HTML preview will display in RStudio’s Viewer (if you’re in\\nRStudio) or your default browser otherwise. The reprex is automatically copied to\\nyour clipboard (on RStudio Server or Cloud, you will need to copy this yourself):\\n``` r\\ny <- 1:4\\nmean(y)\\n#> [1] 2.5\\n```\\nThis text is formatted in a special way, called Markdown, which can be pasted to sites\\nlike StackOverflow or GitHub, which will automatically render it to look like code.\\nHere’s what that Markdown would look like rendered on GitHub:\\ny <- 1:4\\nmean(y)\\n#> [1] 2.5\\nAnyone else can copy, paste, and run this immediately.\\n112 | Chapter 8: Workflow:  Getting Help\\n\\nThere are three things you need to include to make your example reproducible:\\nrequired packages, data, and code.\\n•Packages  should be loaded at the top of the script so it’s easy to see which ones the •\\nexample needs. This is a good time to check that you’re using the latest version of\\neach package; you may have discovered a bug that’s been fixed since you installed\\nor last updated the package. For packages in the tidyverse, the easiest way to\\ncheck is to run tidyverse_update() .\\n•The easiest way to include data  is to use dput()  to generate the R code needed •\\nto re-create it. For example, to re-create the mtcars  dataset in R, perform the\\nfollowing steps:\\n—Run dput(mtcars)  in R.\\n—Copy the output.\\n—In reprex, type mtcars <- , and then paste.\\nTry to use the smallest subset of your data that still reveals the problem.\\n•Spend a little bit of time ensuring that your code  is easy for others to read: •\\n—Make sure you’ve used spaces and your variable names are concise yet—\\ninformative.\\n—Use comments to indicate where your problem lies.—\\n—Do your best to remove everything that is not related to the problem.—\\nThe shorter your code is, the easier it is to understand and the easier it is to fix.\\nFinish by checking that you have actually made a reproducible example by starting a\\nfresh R session and copying and pasting your script.\\nCreating reprexes is not trivial, and it will take some practice to learn to create good,\\ntruly minimal reprexes. However, learning to ask questions that include the code and\\ninvesting the time to make it reproducible will continue to pay off as you learn and\\nmaster R.\\nInvesting in Yourself\\nY ou should also spend some time preparing yourself to solve problems before they\\noccur. Investing a little time in learning R each day will pay off handsomely in the\\nlong run. One way is to follow what the tidyverse team is doing on the tidyverse blog .\\nTo keep up with the R community more broadly, we recommend reading R Weekly :\\nit’s a community effort to aggregate the most interesting news in the R community\\neach week.\\nInvesting in Yourself | 113\\n\\nSummary\\nThis chapter concludes the “Whole Game” part of the book. Y ou’ve now seen the\\nmost important parts of the data science process: visualization, transformation, tidy‐\\ning, and importing.', start_char_idx=240348, end_char_idx=244483, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7869754513484729),\n",
       " NodeWithScore(node=TextNode(id_='3663fe51-16c9-4a47-8615-d46f0d78b3e1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='6a01f67d-814e-4dcb-9267-5939e8474d9f', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='066f44e9c566b4ad5a8851673fe629f8cd260e4f653cd4067a318e8c4adfc5ea'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e9a71066-217d-4f74-9d13-c2fd2def6eaf', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8cd34d4e56e923892d3e700abdba712518d5c2fe713d3f6d4a3965894dcec783'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0aa3a0a0-adda-4cf1-95cb-760ffdf97887', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='61560c78acbf042a608e975e48f7098b5d336580d21534d28fd558d69e4656c0')}, hash='d672dfdb55f975d4242c3c0a119584e83505f7a9cc3dbd8ee3f2a41286239e97', text='This makes it possible to lay out small\\namounts of data in an easy-to-read form:\\ntribble(\\n  ~x, ~y, ~z,\\n  1, \"h\", 0.08,\\n  2, \"m\", 0.83,\\n  5, \"g\", 0.60\\n)\\n#> # A tibble: 3 × 3\\nData Entry | 109\\n\\n#>   x         y     z\\n#>   <chr> <dbl> <dbl>\\n#> 1        1 h  0.08\\n#> 2        2 m  0.83\\n#> 3        5 g  0.6\\nSummary\\nIn this chapter, you learned how to load CSV files with read_csv()  and to do your\\nown data entry with tibble()  and tribble() . Y ou’ve learned how CSV files work,\\nsome of the problems you might encounter, and how to overcome them. We’ll come\\nto data import a few times in this book: Chapter 20  will show you how to load data\\nfrom Excel and Google Sheets, Chapter 21  from databases, Chapter 22  from parquet\\nfiles, Chapter 23  from JSON, and Chapter 24  from websites.\\nWe’re just about at the end of this section of the book, but there’s one important last\\ntopic to cover: how to get help. So in the next chapter, you’ll learn some good places\\nto look for help, how to create a reprex to maximize your chances of getting good\\nhelp, and some general advice on keeping up with the world of R.\\n110 | Chapter 7: Data Import\\n\\nCHAPTER 8\\nWorkflow:  Getting Help\\nThis book is not an island; there is no single resource that will allow you to master\\nR. As you begin to apply the techniques described in this book to your own data, you\\nwill soon find questions that we do not answer. This section describes a few tips on\\nhow to get help and to help you keep learning.\\nGoogle Is Your Friend\\nIf you get stuck, start with Google. Typically adding “R” to a query is enough to\\nrestrict it to relevant results: if the search isn’t useful, it often means that there aren’t\\nany R-specific results available. Additionally, adding package names like “tidyverse”\\nor “ggplot2” will help narrow down the results to code that will feel more familiar\\nto you as well, e.g., “how to make a boxplot in R” versus “how to make a boxplot\\nin R with ggplot2. ” Google is particularly useful for error messages. If you get an\\nerror message and you have no idea what it means, try googling it! Chances are that\\nsomeone else has been confused by it in the past, and there will be help somewhere\\non the web. (If the error message isn’t in English, run Sys.setenv(LANGUAGE = \"en\")\\nand rerun the code; you’re more likely to find help for English error messages.)\\nIf Google doesn’t help, try Stack Overflow . Start by spending a little time searching\\nfor an existing answer, including [R], to restrict your search to questions and answers\\nthat use R.\\nMaking a reprex\\nIf your googling doesn’t find anything useful, it’s a really good idea to prepare a\\nreprex , short for minimal reproducible example. A good reprex makes it easier for\\nother people to help you, and often you’ll figure out the problem yourself in the\\ncourse of making it. There are two parts to creating a reprex:\\n111\\n\\n•First, you need to make your code reproducible. This means you need to capture•\\neverything, i.e., include any library()  calls and create all necessary objects. The\\neasiest way to make sure you’ve done this is using the reprex package.\\n•Second, you need to make it minimal. Strip away everything that is not directly•\\nrelated to your problem. This usually involves creating a much smaller and\\nsimpler R object than the one you’re facing in real life or even using built-in data.\\nThat sounds like a lot of work! And it can be, but it has a great payoff:\\n•80% of the time, creating an excellent reprex reveals the source of your problem.•\\nIt’s amazing how often the process of writing up a self-contained and minimal\\nexample allows you to answer your own question.\\n•The other 20% of the time, you will have captured the essence of your problem•\\nin a way that is easy for others to play with. This substantially improves your\\nchances of getting help!', start_char_idx=237328, end_char_idx=241134, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7834975323233087)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec453825-6a68-49ce-bc23-54d81f2fe9b2",
   "metadata": {},
   "source": [
    "## Trying chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02eda7e-5b03-4588-a648-943ef6111e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(fp)\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde5c1ef-0f8d-4557-b25c-de053d730d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b95d57fc-b8c8-41b6-9dd3-b5f5b28af736",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2dae02e-ecd8-441c-91dd-3c3d92a5d645",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformer python package. This is needed in order to for SentenceTransformersTokenTextSplitter. Please install it with `pip install sentence-transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/langchain/text_splitter.py:759\u001b[0m, in \u001b[0;36mSentenceTransformersTokenTextSplitter.__init__\u001b[0;34m(self, chunk_overlap, model_name, tokens_per_chunk, **kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 759\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m token_splitter \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformersTokenTextSplitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_overlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens_per_chunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/langchain/text_splitter.py:761\u001b[0m, in \u001b[0;36mSentenceTransformersTokenTextSplitter.__init__\u001b[0;34m(self, chunk_overlap, model_name, tokens_per_chunk, **kwargs)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 761\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    762\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformer python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    763\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is needed in order to for SentenceTransformersTokenTextSplitter. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    764\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m model_name\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name)\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import sentence_transformer python package. This is needed in order to for SentenceTransformersTokenTextSplitter. Please install it with `pip install sentence-transformers`."
     ]
    }
   ],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a86052-4cc9-4356-81b8-c5b97ad7156e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
